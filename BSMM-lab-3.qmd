---
title: "BSMM-lab-3"
subtitle: "BSMM 8740 Fall 2023"
author: "Jay Ashokkumar Patel"
date: "13 October 2023"
format: html
editor: visual
self-contained: true
---

## Setup

Load packages and data:

```{r load-pkg-data}
#| message: false
boston_cocktails <- readr::read_csv('data/boston_cocktails.csv')
```

## Exercises

### Exercise 1

```{r}
# Loading the required libraries #
library(magrittr)   # the pipe
library(tidyverse)  # for data wrangling + visualization
library(tidymodels) # for modeling
library(gt) # for pretty tables


boston_cocktails <- readr::read_csv('data/boston_cocktails.csv') # Loading the Boston Cocktail Recipes data set #

# Using skim to assess dataset quality
skimr::skim(boston_cocktails)

# Using introduce to explore variables in the dataset 
DataExplorer::introduce(boston_cocktails)

# Calculating the median measure number
median_measure_number <- median(boston_cocktails$measure_number)
print(median_measure_number)

```

The median measure amount across across all cocktails is \_1\_\_.

### Exercise 2

```{r}

#loading the libraries #

library(tidyverse)
library(janitor)

#selecting the columns mentioned #
select_columns <- boston_cocktails |>
  select(name, category, ingredient, measure_number)

# Pivoting the table in order to create columns for each ingredient and fill the missing values with zero #
pivoted_table <- select_columns |>
  pivot_wider(names_from = ingredient, values_from = measure_number, values_fill = 0)

# Cleaning column names #
cleaned_table <- pivoted_table |>
  janitor::clean_names()


# Evaluating how much gin is in the cocktail called Leap Frog Highball
gin_in_leap_frog_highball <- cleaned_table |>
  filter(name == "Leap Frog Highball") |>
  select(gin)

print(gin_in_leap_frog_highball)
```

The **Leap Frog Highball** contains \_\_2\_ of gin

### Exercise 3

```{r}

library(recipes)


boston_cocktails <- read.csv("data/boston_cocktails.csv", header = TRUE)
View(boston_cocktails)

# Creating a recipe object using the loaded dataset
recipe_obj <- recipe(~ ., data = boston_cocktails) |>
  update_role(name, category, new_role = "id") |>
  step_dummy(all_nominal()) |>
  step_normalize(all_numeric()) |>
  step_pca(all_numeric(), num_comp = 3)

# Preparing the data
prepped_data <- prep(recipe_obj)

# Counting the number of predictor variables prepped by the recipe
num_predictor_vars <- length(prepped_data$predictors)
print(num_predictor_vars)

```

0 predictor variables are prepped by the recipe.

### Exercise 4

```{r}
# Summarizing the data to find the most used ingredient on average
ingredient_summary <- boston_cocktails |>
  group_by(ingredient) |>
  summarize(avg_measure_number = mean(measure_number, na.rm = TRUE)) |>
  arrange(desc(avg_measure_number))

most_used_ingredient <- ingredient_summary$ingredient[1]

print(most_used_ingredient ) # display the most used ingredient on an average #

```

On average the most used ingredient in the Boston Cocktails dataset is cranberry juice.

### Exercise 5

```{r}
library(recipes)
library(dplyr)
library(forcats)
library(ggplot2)

# Assuming 'boston_cocktails' is your dataset
numeric_columns <- select_if(boston_cocktails, is.numeric)

boston_cocktails_recipe <-
  recipe(~., data = numeric_columns) %>% 
  update_role(., row_id, ingredient_number, measure_number) %>% 
  step_naomit(all_predictors()) %>% 
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), id = "pca") %>% 
  prep()

boston_cocktails_pca <- 
  boston_cocktails_recipe %>% 
  tidy(id = "pca", matrix = "X") # Use matrix = "X" to keep the original data matrix

# Filtering for components PC1 to PC5 and mutating them as factors
boston_cocktails_pca_filtered <- boston_cocktails_pca %>%
  filter(component %in% c("PC1", "PC2", "PC3", "PC4", "PC5")) %>%
  mutate(component = fct_inorder(component))

# Creating PCA plot
ggplot(boston_cocktails_pca_filtered, aes(x = value, y = terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL) +
  theme(axis.text = element_text(size = 7),
        axis.title = element_text(size = 14, face = "bold"))



```

Describe describe the drinks represented by PC1?

-   When row_id falls between 0 and 0.25 and exhibits a positive loading on PC1, it positively affects higher PC1 values within this interval.

-   For measure_number, if it ranges between 0 and -0.7 and shows a negative loading on PC1, it detracts from higher PC1 values within that span.

-   Similarly, if ingredient_number is between 0 and 0.7 with a positive PC1 loading, it positively influences higher PC1 values within this range.

### Exercise 6

```{r}
# Loading required libraries
library(dplyr)
library(gt)

# Assuming 'boston_cocktails_pca_filtered' contains your PCA data
# Replace it with your actual data if necessary

# Creating a function to color cells based on value
color_cells <- function(x) {
  ifelse(x < 0, "red", "green")
}

# Slicing the top 8 ingredients by component based on absolute value
top_ingredients_table <- boston_cocktails_pca_filtered %>%
  filter(component %in% c("PC1", "PC2", "PC3", "PC4")) %>%
  group_by(component) %>%
  slice_max(order_by = abs(value), n = 8) %>%
  ungroup() %>%
  pivot_wider(names_from = component, values_from = terms)

# Modifying the table to add cell background colors using gt
for (col in names(top_ingredients_table)[-1]) {
  top_ingredients_table[[col]] <- sapply(top_ingredients_table[[col]], function(x) {
    cell_style <- color_cells(x)
    sprintf('<span style="background-color: %s">%s</span>', cell_style, x)
  })
}

# Creating the gt table
table_pca_ingredients <- top_ingredients_table %>%
  gt() %>%
  tab_style(
    style = cell_fill(
      color = color_cells(0)
    ),
    locations = cells_body()
  )

# Printing the table
table_pca_ingredients
```

The characteristic alcoholic beverage of each of the first 4 principle components is 0.

### Exercise 7

```{r}
# Loading the required libraries
library(dplyr)
library(recipes)
library(ggplot2)


# Assuming 'boston_cocktails' is your data frame

# Creating the PCA recipe
rec <- recipe(~., data = boston_cocktails)
pca_trans <- rec %>%
  step_normalize(all_numeric()) %>%
  step_pca(all_numeric(), num_comp = 3)
pca_estimates <- prep(pca_trans, training = boston_cocktails)
pca_data <- bake(pca_estimates, boston_cocktails)

# Extending range for the plot
rng <- extendrange(c(pca_data$PC1, pca_data$PC2))


# Creating PCA with threshold
with_thresh <- rec %>%
  step_normalize(all_numeric()) %>%
  step_pca(all_numeric(), threshold = 0.99)
with_thresh <- prep(with_thresh, training = boston_cocktails)
baked_with_thresh <- bake(with_thresh, boston_cocktails)

# Printing tidy PCA results
tidy(pca_trans, number = 2)
tidy(pca_estimates, number = 2)

# Creating the scatter plot of PC1 and PC2 with labels
ggplot(pca_data, aes(PC1, PC2, label = name)) +
  geom_point(aes(color = category), alpha = 0.7, size = 2) +
  geom_text(check_overlap = TRUE, hjust = "inward") + 
  labs(color = NULL)

```

How would you interpret the results of a PCA analysis for a client?

In this PCA evaluation, PC1 and PC2 do not clearly differentiate the data points, indicating that the dataset might have a complicated or low-variance configuration. Delving into higher-dimensional components could be necessary to reveal underlying trends.
